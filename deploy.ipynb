{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'qwiklabs-gcp-81966e9357970fe8' # CHANGE\n",
    "BUCKET = 'qwiklabs-gcp-81966e9357970fe8' # CHANGE\n",
    "MODEL_BASE = 'taxi_trained/export/exporter'\n",
    "MODEL_PATH = os.path.join(MODEL_BASE,os.listdir(MODEL_BASE)[-1])\n",
    "MODEL_NAME = 'taxifare'\n",
    "VERSION_NAME = 'v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy for Online Prediction\n",
    "\n",
    "To get our predictions we need to fetch the latest traffic information from BigQuery. Only then can we invoke our tensorflow model.\n",
    "\n",
    "To do this we'll take advantage of [AI Platforms Custom Prediction Routines](https://cloud.google.com/ml-engine/docs/tensorflow/custom-prediction-routines) which allows us to execute custom python code in response to every online prediction request. There are 5 steps to creating a custom prediction routine:\n",
    "\n",
    "1. Upload Model Artifacts to GCS\n",
    "2. Implement Predictor interface \n",
    "3. Package the prediction code and dependencies\n",
    "4. Deploy\n",
    "5. Invoke API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload Model Artifacts to GCS\n",
    "\n",
    "Here we upload our model weights so that AI Platform can access them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://taxi_trained/export/exporter/1564519940/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://taxi_trained/export/exporter/1564519940/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://taxi_trained/export/exporter/1564519940/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://taxi_trained/export/exporter/1564519940/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "-\n",
      "Operation completed over 4 objects/78.9 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r $MODEL_PATH/* gs://$BUCKET/taxifare/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement Predictor Interface\n",
    "\n",
    "Interface Spec: https://cloud.google.com/ml-engine/docs/tensorflow/custom-prediction-routines#predictor-class\n",
    "\n",
    "This tells AI Platform how to load the model artifacts, and is where we specify our custom prediction code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor.py\n",
    "import tensorflow as tf\n",
    "from google.cloud import bigquery\n",
    "\n",
    "class TaxifarePredictor(object):\n",
    "    def __init__(self, predict_fn):\n",
    "      self.predict_fn = predict_fn\n",
    "    \n",
    "    \n",
    "    def predict(self, instances, **kwargs):\n",
    "        bq = bigquery.Client()\n",
    "        query_string = \"\"\"\n",
    "        SELECT\n",
    "          *\n",
    "        FROM\n",
    "          `taxifare.traffic_realtime`\n",
    "        ORDER BY\n",
    "          time DESC\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "        trips = bq.query(query_string).to_dataframe()['trips_last_5min'][0]\n",
    "        instances['trips_last_5min'] = [trips for _ in range(len(list(instances.items())[0][1]))]\n",
    "        predictions = self.predict_fn(instances)\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def from_path(cls, model_dir):\n",
    "        predict_fn = tf.contrib.predictor.from_saved_model(model_dir,'predict')\n",
    "        return cls(predict_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Predictor Class Works Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/export/exporter/1564519940/variables/variables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': array([[7.3234653],\n",
       "        [6.110935 ]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import predictor\n",
    "\n",
    "instances = {'dayofweek' : [6,7],\n",
    "             'hourofday' : [12,11],\n",
    "             'pickuplon' : [-73.99,-73.99], \n",
    "             'pickuplat' : [40.758,40.758],\n",
    "             'dropofflat' : [40.742,40.758],\n",
    "             'dropofflon' : [-73.97,-73.97]}\n",
    "\n",
    "predictor = predictor.TaxifarePredictor.from_path(MODEL_PATH)\n",
    "predictor.predict(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Package Predictor Class and Dependencies\n",
    "\n",
    "We must package the predictor as a tar.gz source distribution package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name='taxifare_custom_predict_code',\n",
    "    version='0.1',\n",
    "    scripts=['predictor.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing taxifare_custom_predict_code.egg-info/PKG-INFO\n",
      "writing top-level names to taxifare_custom_predict_code.egg-info/top_level.txt\n",
      "writing dependency_links to taxifare_custom_predict_code.egg-info/dependency_links.txt\n",
      "reading manifest file 'taxifare_custom_predict_code.egg-info/SOURCES.txt'\n",
      "writing manifest file 'taxifare_custom_predict_code.egg-info/SOURCES.txt'\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating taxifare_custom_predict_code-0.1\n",
      "creating taxifare_custom_predict_code-0.1/taxifare_custom_predict_code.egg-info\n",
      "copying files to taxifare_custom_predict_code-0.1...\n",
      "copying README.md -> taxifare_custom_predict_code-0.1\n",
      "copying predictor.py -> taxifare_custom_predict_code-0.1\n",
      "copying setup.py -> taxifare_custom_predict_code-0.1\n",
      "copying taxifare_custom_predict_code.egg-info/PKG-INFO -> taxifare_custom_predict_code-0.1/taxifare_custom_predict_code.egg-info\n",
      "copying taxifare_custom_predict_code.egg-info/SOURCES.txt -> taxifare_custom_predict_code-0.1/taxifare_custom_predict_code.egg-info\n",
      "copying taxifare_custom_predict_code.egg-info/dependency_links.txt -> taxifare_custom_predict_code-0.1/taxifare_custom_predict_code.egg-info\n",
      "copying taxifare_custom_predict_code.egg-info/top_level.txt -> taxifare_custom_predict_code-0.1/taxifare_custom_predict_code.egg-info\n",
      "Writing taxifare_custom_predict_code-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'taxifare_custom_predict_code-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!python setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://dist/taxifare_custom_predict_code-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  1.1 KiB/  1.1 KiB]                                                \n",
      "Operation completed over 1 objects/1.1 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp dist/taxifare_custom_predict_code-0.1.tar.gz gs://$BUCKET/taxifare/predict_code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy\n",
    "\n",
    "This is similar to how we deploy standard models to AI Platform, with a few extra command line arguments.\n",
    "\n",
    "*Warning: If you get a GCS access error, grant the 'Storage Object Viewer' role on the bucket that contains your artifacts to the service account being used.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.models.create) Resource in project [qwiklabs-gcp-81966e9357970fe8] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n",
      "Creating version (this might take a few minutes)......⠧"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create $MODEL_NAME --regions us-central1 --enable-logging\n",
    "\n",
    "!gcloud beta ai-platform versions create $VERSION_NAME \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin gs://$BUCKET/taxifare/model \\\n",
    "  --runtime-version 1.14 \\\n",
    "  --python-version 3.5 \\\n",
    "  --package-uris gs://$BUCKET/taxifare/predict_code/taxifare_custom_predict_code-0.1.tar.gz \\\n",
    "  --prediction-class predictor.TaxifarePredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Invoke API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Prediction failed: unknown error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5dcdc2bfc29e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Prediction failed: unknown error."
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "\n",
    "instances = {'dayofweek' : [6], \n",
    "             'hourofday' : [12],\n",
    "             'pickuplon' : [-73.99], \n",
    "             'pickuplat' : [40.758],\n",
    "             'dropofflat' : [40.742],\n",
    "             'dropofflon' : [-73.97]}\n",
    "\n",
    "service = googleapiclient.discovery.build('ml', 'v1')\n",
    "name = 'projects/{}/models/{}/versions/{}'.format(PROJECT_ID, MODEL_NAME, VERSION_NAME)\n",
    "\n",
    "response = service.projects().predict(\n",
    "    name=name,\n",
    "    body={'instances': instances}\n",
    ").execute()\n",
    "\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "else:\n",
    "  print(response['predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
